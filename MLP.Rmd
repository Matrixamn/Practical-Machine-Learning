# PRACTICAL MACHINE LEARNING FINAL PROJECT

AUTHOR : Nicolas A. Leali

Date: 20th July of 2014

# Project over View: 
The goal of this project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. You may use any of the other variables to predict with. You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases. 


Data:

The training data for this project are available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

All this data came from  http://groupware.les.inf.puc-rio.br/har.

```{r}
#loading librarys

library(caret)
library(ggplot2)
library(knitr)
library(corrplot)
library(randomForest)

```



```{r}
#Load the data into training and test variables
training <- read.csv("pml-training.csv")

test <- read.csv("pml-testing.csv")
```

```{r}

## We take out all those indicators near to Zero Variance from the data set.

nzv <- nearZeroVar(training)

training <- training[-nzv]
test <- test[-nzv]


#Some variables contains NA values. so we remove them to improve the accuracy of the model.

#Training
NAs <- apply(training, 2, function(x) {
    sum(is.na(x))
})

training2 <-training[, which(NAs == 0)]

#Test
NAs <- apply(test, 2, function(x) {
    sum(is.na(x))
})

test2 <-test[, which(NAs == 0)]



```

We explore the data we have

```{r}
dim(training2)

head(training2)

```

```{r}
#take a look at our outcome variable classes

table(training2$classe)

```



#The original given training set is 19622X93, Because of that We split  the training data set into a smaller training a test dataset to construct the model to predict.

```{r}
set.seed(1234)
trainingpart = createDataPartition(training2$classe, p = 0.02, list = FALSE)
partTraining = training2[ trainingpart,]
partTest =  training2[-trainingpart,]

#Now we have 14718 Rows X 93 Columns

dim(partTraining)


# finally we study the correlation between  variables.

Metd.Cod = cor( partTraining[,-c(grep("timestamp|X|user_name|num_window|new_window",names(partTraining)), length(partTraining))])
corrplot(Metd.Cod, method="number",tl.cex=0.8)



```

## With this exploratory analisys we can start with our Model.



```{r}
#we construct the model  with the  prediction data    where the column class is the outcome and other features are as predictors.

# This is our model
DataModel <- train(partTraining$classe ~ ., method = "rf", trControl = trainControl(method = "cv", number = 4), 
    partTraining)

summary(DataModel)





```


```{r}
DataModel$finalModel
```


```{r}
print(DataModel, digits = 3)
```


```{r}
# With this code we get de prediction data

Prediction <- predict(DataModel, partTest)

##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
##  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
## Levels: A B C D E

```

## Expected out put Error 

```{r}
Error <- confusionMatrix(Prediction, partTest$classe)
Error

```
#The expect error por this analysis is 0.997%. Which is inside what we where expecting.
# So this indicated that we can give good prediction about this topic with the accelerometers technology.

## The 20 data cases.

```{r}

answers<- as.vector(Prediction[1:20])
Last_Point = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
Last_Point(answers)

```




